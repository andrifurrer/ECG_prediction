{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import psutil\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.profiler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Add the parent directory, i.e. transformer, means parent directory of 'scripts' and 'notebooks', to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import classes and functions\n",
    "from scripts.m1_functions import *\n",
    "from scripts.m1_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_filtered_imu():\n",
    "    '''\n",
    "    Read in csv file of the entire dataset. If not already created, read-in all individual csv files for all subjects and actions. \n",
    "    Add subject and action column for labeling the actions. Filter the signals with an appropriate bandpass filter.\n",
    "    '''\n",
    "    if os.path.exists('../data/Finger/csv/finger_dataset_filtered_imu.csv'):\n",
    "        # Reading the CSV file\n",
    "        df_filtered = pd.read_csv(\n",
    "                    '../data/Finger/csv/finger_dataset_filtered_imu.csv',\n",
    "                    sep=',',           \n",
    "                    header=0,          \n",
    "                    na_values=['NA', '']  \n",
    "        )\n",
    "        return df_filtered\n",
    "    \n",
    "    else:                    \n",
    "        actions = [\"run\", \"sit\", \"walk\"]\n",
    "        subjects = [i for i in range(1 , 23)]\n",
    "        df_data = pd.DataFrame()\n",
    "        for subject in subjects:\n",
    "            for action in actions:\n",
    "                file_path = f'../data/Finger/csv/s{str(subject)}_{action}.csv'\n",
    "                # Reading the CSV file\n",
    "                try:\n",
    "                    df_temp = pd.read_csv(\n",
    "                        file_path,\n",
    "                        sep=',',           \n",
    "                        header=0,          \n",
    "                        na_values=['NA', '']  \n",
    "                    )\n",
    "                    # Adding a column with the current action and subject\n",
    "                    df_temp['action'] = action\n",
    "                    df_temp['subject'] = subject\n",
    "                    df_data = pd.concat([df_data, df_temp], ignore_index=True)\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File not found: {file_path}\")\n",
    "        # Define sampling frequency, bandpass range and apply bandpass filter\n",
    "        df_filtered = pd.DataFrame()\n",
    "        fs = 500  \n",
    "        lowcut = 0.4\n",
    "        highcut = 10\n",
    "        df_filtered['ecg']  = bandpass_filter(df_data['ecg'], lowcut, highcut, fs, order=4)\n",
    "        df_filtered['red ppg'] = bandpass_filter(df_data['pleth_4'], lowcut, highcut, fs, order=4)\n",
    "        df_filtered['ir ppg'] = bandpass_filter(df_data['pleth_5'], lowcut, highcut, fs, order=4)\n",
    "        df_filtered['green ppg'] = bandpass_filter(df_data['pleth_6'], lowcut, highcut, fs, order=4)\n",
    "        df_filtered['action'] = df_data['action']\n",
    "        df_filtered['subject'] = df_data['subject']\n",
    "        df_filtered['a_x'] = df_data['a_x']\n",
    "        df_filtered['a_y'] = df_data['a_y']\n",
    "        df_filtered['a_z'] = df_data['a_z']\n",
    "        df_filtered['g_x'] = df_data['g_x']\n",
    "        df_filtered['g_y'] = df_data['g_y']\n",
    "        df_filtered['g_z'] = df_data['g_z']\n",
    "        # Store the DataFrame to a csv file\n",
    "        df_filtered.to_csv('../data/Finger/csv/finger_dataset_filtered_imu.csv', index=False)\n",
    "        return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = data_loader_filtered_imu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = data_loader_filtered_imu()\n",
    "df_original = data_loader_original()\n",
    "df_filtered_single = data_loader_filtered_single(subject=10, action='sit')\n",
    "df_original_single = data_loader_original_single(subject=10, action='sit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_group_action_imu(df):\n",
    "    '''\n",
    "    Group the data by subject and actions, and normalize each (subject, action) pair\n",
    "    '''\n",
    "    # Initialize a dictionary to store scalers for each subject-action group\n",
    "    scalers = {}\n",
    "\n",
    "    # Placeholder for normalized data\n",
    "    normalized_data = []\n",
    "\n",
    "    # Group data by subject and action\n",
    "    grouped_data = df.groupby(['subject', 'action'])\n",
    "    print(grouped_data.first())\n",
    "\n",
    "    for (subject, action), group in grouped_data:\n",
    "        # Initialize scalers for PPG (inputs) and ECG (targets)\n",
    "        scaler_input = MinMaxScaler(feature_range=(-1, 1))  # For PPG signals\n",
    "        scaler_target = MinMaxScaler(feature_range=(-1, 1))  # For ECG signals\n",
    "\n",
    "        # Fit and transform the PPG and IMU columns (inputs)\n",
    "        ppg_normalized = scaler_input.fit_transform(group[['red ppg', 'ir ppg', 'green ppg', 'a_x', 'a_y', 'a_z', 'g_x', 'g_y', 'g_z']])\n",
    "\n",
    "        # Fit and transform the ECG column (target)\n",
    "        ecg_normalized = scaler_target.fit_transform(group[['ecg']])\n",
    "\n",
    "        # Save the scalers for this subject-action group\n",
    "        scalers[(subject, action)] = {'input_scaler': scaler_input, 'target_scaler': scaler_target}\n",
    "        # Inspect original scalers (collective normalization)\n",
    "        print(scalers[(subject, action)]['input_scaler'].data_min_, scalers[(subject, action)]['input_scaler'].data_max_)\n",
    "\n",
    "        # Create a copy of the group with normalized values\n",
    "        group_normalized = group.copy()\n",
    "        group_normalized[['red ppg', 'ir ppg', 'green ppg', 'a_x', 'a_y', 'a_z', 'g_x', 'g_y', 'g_z']] = ppg_normalized\n",
    "        group_normalized[['ecg']] = ecg_normalized\n",
    "\n",
    "        # Append the normalized group to the list\n",
    "        normalized_data.append(group_normalized)\n",
    "\n",
    "    # Combine all normalized groups back into a single DataFrame\n",
    "    normalized_df = pd.concat(normalized_data).reset_index(drop=True)\n",
    "    return normalized_df, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ecg     red ppg      ir ppg  green ppg        a_x  \\\n",
      "subject action                                                              \n",
      "1       run      174.974839   15.310121   36.949744   2.448764   1.264203   \n",
      "        sit    -2385.170850  -60.995543 -207.180828 -27.146285   4.298409   \n",
      "        walk    3103.829398  -72.695792 -206.359678 -41.808654   9.262442   \n",
      "2       run    -4260.135210   62.017004  212.866797 -69.501723   1.019383   \n",
      "        sit     -512.615543   97.781635  205.756513  32.764378   8.602206   \n",
      "...                     ...         ...         ...        ...        ...   \n",
      "21      sit    -3314.057062   76.640336  125.034479  10.588793   1.431806   \n",
      "        walk   -1528.150596 -104.075541  -65.526139 -27.216916  11.171316   \n",
      "22      run    -2490.481940  -11.945232  147.605710  48.883196   4.551610   \n",
      "        sit     4405.402837  -30.184581  -41.718308   0.660463   1.579057   \n",
      "        walk     589.877914 -106.935586 -130.246244 -37.167680   9.995703   \n",
      "\n",
      "                     a_y        a_z       g_x       g_y       g_z  \n",
      "subject action                                                     \n",
      "1       run     0.071231 -10.321930 -0.508413  0.666570 -0.076496  \n",
      "        sit     1.371349  -8.450766  0.007759 -0.000482  0.004583  \n",
      "        walk   -2.804352   6.942940  0.547324 -0.082509  0.523109  \n",
      "2       run    -7.622330   1.657471  0.347413  0.375985 -0.301256  \n",
      "        sit    -3.817749  -2.365592 -0.005860 -0.001790 -0.004309  \n",
      "...                  ...        ...       ...       ...       ...  \n",
      "21      sit     1.316279  -9.376770 -0.013019  0.007589 -0.000288  \n",
      "        walk   -1.367757  -1.311491  2.727149  0.865939 -1.038270  \n",
      "22      run    -8.196967  -0.898470  1.275965 -0.483460 -1.211321  \n",
      "        sit     1.166036  -9.377369 -0.000907  0.001242 -0.001429  \n",
      "        walk   -1.434200   0.032922  0.248103  0.264234 -0.821429  \n",
      "\n",
      "[66 rows x 10 columns]\n",
      "[-198.97982099 -580.39270088  -91.15962911   -2.441612     -2.55175\n",
      "  -15.272194     -1.549991     -2.247505     -2.228763  ] [ 1.41974632e+03  4.16234757e+03  6.44940509e+02  6.87410400e+00\n",
      "  5.43631200e+00 -3.55317600e+00  1.91749700e+00  2.65664700e+00\n",
      "  1.75765000e+00]\n",
      "[-1.40507220e+03 -4.22371065e+03 -6.53142260e+02  4.14158200e+00\n",
      "  1.29592800e+00 -8.56868600e+00 -5.29620000e-02 -3.56360000e-02\n",
      " -3.45660000e-02] [ 1.01854616e+03  2.30974737e+03  1.34381393e+02  4.34689500e+00\n",
      "  1.44916400e+00 -8.39928700e+00  5.39660000e-02  3.24080000e-02\n",
      "  3.16150000e-02]\n",
      "[-1.06233131e+03 -3.03497864e+03 -1.97764008e+02  3.82014300e+00\n",
      " -1.01321790e+01 -1.44377700e+00 -4.38812100e+00 -2.74957200e+00\n",
      " -4.36573000e+00] [ 733.05778885 2254.1951499   507.62000211   18.686499     11.397579\n",
      "   12.746182      4.338524      3.450628      4.360915  ]\n",
      "[-1.36836799e+03 -3.06758805e+03 -5.69438802e+02 -3.56335200e+00\n",
      " -1.96143000e+01 -1.31208900e+00 -2.49994900e+00 -2.45912600e+00\n",
      " -2.45791700e+00] [ 1.18801875e+03  3.69052441e+03  2.25911649e+02  7.08480400e+00\n",
      " -8.58964000e-01  1.16555680e+01  2.61979000e+00  2.48524100e+00\n",
      "  3.06476400e+00]\n",
      "[-5.98047335e+02 -1.12162639e+03 -1.08757379e+02  8.31249300e+00\n",
      " -4.26967800e+00 -2.50386400e+00 -1.98809000e-01 -5.53200000e-02\n",
      " -1.08041000e-01] [ 3.23712274e+03  5.17143980e+03  9.08547618e+01  8.65428300e+00\n",
      " -3.74651800e+00 -2.21415100e+00  1.06127000e-01  5.22730000e-02\n",
      "  1.54018000e-01]\n",
      "[-7.87744981e+03 -1.06513506e+04 -1.18362131e+03  2.20756600e+00\n",
      " -3.18504900e+00  6.62569200e+00 -1.65398300e+00 -1.89439400e+00\n",
      " -2.19173000e+00] [1.09902510e+03 1.52775905e+03 1.72305283e+02 8.71054900e+00\n",
      " 5.19867500e+00 1.22050650e+01 1.78940400e+00 1.33700200e+00\n",
      " 1.71066000e+00]\n",
      "[-1.12409355e+03 -1.57945272e+03 -2.02930236e+02  1.40546800e+00\n",
      " -1.12257860e+01 -8.42682300e+00 -2.11675000e+00 -9.86612000e-01\n",
      " -1.74007500e+00] [ 7.83564921e+03  1.06528602e+04  1.20019494e+03  8.46393400e+00\n",
      " -2.44101300e+00  1.20913000e-01  1.98751000e+00  1.22317900e+00\n",
      "  1.94233400e+00]\n",
      "[-9.47965905e+02 -1.50390793e+03 -1.34364595e+02  4.27446700e+00\n",
      " -1.52877600e+00 -8.46154000e+00 -1.11551000e-01 -1.01404000e-01\n",
      " -3.94250000e-02] [ 3.06648765e+03  5.04594358e+03  4.03367036e+02  4.81857600e+00\n",
      " -1.04572100e+00 -8.09101900e+00  1.28537000e-01  7.49000000e-02\n",
      "  3.80740000e-02]\n",
      "[-3.06928860e+03 -5.01610081e+03 -3.83896118e+02  5.56620400e+00\n",
      " -5.64521700e+00  1.42821400e+00 -2.41482100e+00 -1.41209900e+00\n",
      " -1.49819300e+00] [455.89871983 746.23353253  88.36309899  11.516697     3.039594\n",
      "   7.970704     2.871102     1.576946     1.274599  ]\n",
      "[-215.59980955 -427.1399939   -97.35051359    1.355187    -10.209995\n",
      "  -11.325151     -2.336227     -1.440046     -1.683467  ] [ 1.79120334e+03  3.17054763e+03  3.57603456e+02  8.05450500e+00\n",
      " -9.37976000e-01 -2.52780700e+00  2.00891900e+00  1.10597400e+00\n",
      "  2.15194300e+00]\n",
      "[-4.43480076e+02 -2.88103973e+02 -2.10813772e+02  3.96799300e+00\n",
      " -1.79933400e+00 -9.20497700e+00 -4.43889000e-01 -6.11658000e-01\n",
      " -9.56660000e-02] [ 1.53914481e+02  1.56132332e+03  1.81860499e+02  5.12864200e+00\n",
      "  4.27387000e-01 -7.49183900e+00  8.40573000e-01  3.42967000e-01\n",
      "  1.54142000e-01]\n",
      "[-3.48869149e+03 -4.71337537e+03 -3.71662047e+02  5.30761700e+00\n",
      " -1.08169560e+01 -2.14591300e+00 -2.94410300e+00 -2.61225500e+00\n",
      " -2.94662400e+00] [498.00295742 773.00535826 190.80428072  14.227072     6.401823\n",
      "   6.460484     4.108188     1.771508     2.508812  ]\n",
      "[-1.52442328e+03 -3.77110280e+03 -1.25716089e+02 -1.07565000e+00\n",
      " -1.44323840e+01 -8.99607300e+00 -2.04760000e+00 -2.00839800e+00\n",
      " -1.55710900e+00] [ 3.36098015e+03  4.47485478e+03  3.46298111e+02  7.33920000e+00\n",
      " -2.84565400e+00  8.39809000e-01  2.48876500e+00  1.43725300e+00\n",
      "  1.27147800e+00]\n",
      "[-6.85164528e+02 -9.54863894e+02 -1.28958198e+02  2.53977900e+00\n",
      " -4.33851400e+00 -8.64470600e+00 -2.78968000e-01 -1.20188000e-01\n",
      " -1.08993000e-01] [ 4.91643498e+03  6.66354858e+03  1.46580032e+02  4.10865900e+00\n",
      " -3.32272300e+00 -7.31346200e+00  1.92952000e-01  1.60913000e-01\n",
      "  1.20442000e-01]\n",
      "[-5.04427826e+03 -6.87546475e+03 -2.02171311e+02  4.42950000e-01\n",
      " -1.40492930e+01 -2.48770200e+00 -3.27600200e+00 -1.26443200e+00\n",
      " -2.38003800e+00] [1.24446827e+03 2.80962511e+03 9.97247787e+02 1.31490270e+01\n",
      " 8.43999000e-01 6.84237900e+00 2.68757200e+00 1.23711300e+00\n",
      " 2.88391300e+00]\n",
      "[-392.93220303 -875.87963413 -976.11299439   -4.413337    -19.6143\n",
      "   -3.472368     -2.740617     -2.803203     -2.645822  ] [3.74876081e+02 1.73687939e+03 2.22987090e+02 6.31562800e+00\n",
      " 1.57307100e+00 1.23355560e+01 4.33777300e+00 1.94115700e+00\n",
      " 2.45807100e+00]\n",
      "[-3.22947250e+02 -6.62786299e+02 -1.62775752e+02  3.14135300e+00\n",
      " -3.97458000e-01 -9.00026300e+00 -1.78617000e-01 -6.18370000e-02\n",
      " -3.98790000e-02] [ 1.96518064e+03  2.80825147e+03  3.53948561e+02  3.76028500e+00\n",
      "  1.18578900e+00 -8.76083100e+00  2.12874000e-01  5.72080000e-02\n",
      "  5.43990000e-02]\n",
      "[-2.00996804e+03 -2.94245250e+03 -3.91771588e+02  3.76208100e+00\n",
      " -1.24624550e+01  6.94952000e-01 -2.84874300e+00 -1.32073200e+00\n",
      " -3.07220000e+00] [1.01630811e+04 9.14150591e+02 1.06252291e+02 1.46095650e+01\n",
      " 2.06929400e+00 1.07672740e+01 4.24083300e+00 1.40745100e+00\n",
      " 3.29391700e+00]\n",
      "[-1.02407084e+04 -8.67197246e+02 -1.36152109e+02 -2.80495000e+00\n",
      " -1.79269010e+01 -7.91743000e+00 -2.13333600e+00 -2.95363700e+00\n",
      " -2.38792800e+00] [ 1.36915740e+03  2.01221318e+03  4.20583316e+01  5.47043100e+00\n",
      " -1.46053700e+00  5.68711800e+00  3.86725600e+00  1.67087900e+00\n",
      "  2.24045000e+00]\n",
      "[-2.60817586e+02 -5.89316267e+02 -3.36985730e+01  5.17353500e+00\n",
      " -5.49497300e+00 -6.02950600e+00 -1.93460000e-01 -1.01215000e-01\n",
      " -5.74930000e-02] [ 1.92823247e+03  4.47547973e+03  2.49358043e+02  5.70866600e+00\n",
      " -5.05920600e+00 -5.51831800e+00  1.13341000e-01  7.37570000e-02\n",
      "  3.33220000e-02]\n",
      "[-1.78030748e+04 -6.40341107e+03 -1.08213130e+03  6.16478500e+00\n",
      " -5.58835200e+00  4.42950000e-01 -2.87583700e+00 -2.31087300e+00\n",
      " -1.86128000e+00] [2.42967419e+03 9.05468786e+02 1.49133292e+02 1.33782840e+01\n",
      " 2.65410800e+00 1.06900570e+01 3.59467800e+00 1.92335100e+00\n",
      " 2.19224600e+00]\n",
      "[-4.35103747e+03 -7.92631830e+03 -1.09607550e+03  5.06998000e-01\n",
      " -1.44144270e+01 -9.45578300e+00 -3.84753100e+00 -3.99804400e+00\n",
      " -4.20697700e+00] [1.77558496e+04 6.25722574e+03 1.04646041e+03 1.56079980e+01\n",
      " 4.70843700e+00 9.26902600e+00 3.29184600e+00 4.05667600e+00\n",
      " 4.35907800e+00]\n",
      "[-6.29725714e+02 -1.02043022e+03 -1.86050438e+02  8.32027000e-01\n",
      "  5.67455000e-01 -1.03392890e+01 -7.01891000e-01 -1.20023000e-01\n",
      " -1.63305000e-01] [ 4.76608901e+03  7.96907202e+03  1.16816124e+03  2.87259000e+00\n",
      "  2.52541300e+00 -8.60938900e+00  7.18794000e-01  1.32316000e-01\n",
      "  1.28582000e-01]\n",
      "[-4.83725294e+03 -7.90088497e+03 -1.21895412e+03  2.70379000e+00\n",
      " -1.24929830e+01 -8.02457600e+00 -4.38789500e+00 -4.22268400e+00\n",
      " -4.36756800e+00] [4.65539993e+03 1.22656174e+03 4.11116564e+02 1.53057150e+01\n",
      " 4.54861600e+00 8.02816800e+00 4.33875100e+00 3.95587400e+00\n",
      " 4.14162700e+00]\n",
      "[-4.69281160e+03 -4.00750853e+03 -6.26282856e+02 -3.57951000e-01\n",
      " -1.96143000e+01 -1.21320380e+01 -4.38887800e+00 -4.30050600e+00\n",
      " -4.08051300e+00] [6.30947036e+02 7.68046705e+03 2.21387196e+02 1.89426920e+01\n",
      " 6.73044400e+00 9.07329000e+00 4.33776800e+00 3.17376900e+00\n",
      " 4.28460300e+00]\n",
      "[-4.64137823e+02 -5.17329084e+02 -7.50399916e+01  4.21401000e+00\n",
      "  9.37378000e-01 -8.69139500e+00 -4.18710000e-01 -3.53908000e-01\n",
      " -2.13944000e-01] [ 3.49174778e+03  4.03523649e+03  6.22569195e+02  5.81880500e+00\n",
      "  4.27386800e+00 -7.20272400e+00  3.60676000e-01  1.86190000e-01\n",
      "  2.06043000e-01]\n",
      "[-1.38620517e+04 -5.83489970e+03 -1.35816134e+03  4.32055700e+00\n",
      " -1.10899090e+01 -9.84964900e+00 -4.13893600e+00 -4.33046700e+00\n",
      " -4.20115700e+00] [1897.74016269  893.60181527  191.09042498   14.507806      3.852467\n",
      "    7.378109      4.337768      2.941272      4.136795  ]\n",
      "[-1.82868411e+03 -7.55281191e+02 -2.17148600e+02 -1.37673600e+00\n",
      " -1.96143000e+01 -1.24163640e+01 -3.61541300e+00 -2.17053500e+00\n",
      " -3.16107200e+00] [1.38737218e+04 5.88434270e+03 1.35029493e+03 1.52907500e+01\n",
      " 3.14913400e+00 1.90887500e+00 4.33078100e+00 2.85292900e+00\n",
      " 2.37559100e+00]\n",
      "[-2.30641290e+02 -1.13874281e+03 -1.09056466e+02  5.45247400e+00\n",
      "  2.89413900e+00 -7.32962300e+00 -1.66301000e-01 -1.28258000e-01\n",
      " -2.82150000e-02] [ 1.56455059e+03  2.20617612e+03  5.37817706e+02  5.80024900e+00\n",
      "  4.10087800e+00 -6.81903400e+00  2.47161000e-01 -4.15710000e-02\n",
      "  1.54081000e-01]\n",
      "[-1.40755547e+03 -1.95626556e+03 -4.03620610e+02  6.97227000e+00\n",
      " -1.07684700e+00  3.37898900e+00 -1.65702800e+00 -1.24693600e+00\n",
      " -8.18520000e-01] [1.85724194e+03 2.15132024e+03 2.80574600e+02 1.04566100e+01\n",
      " 2.28957200e+00 7.73127100e+00 1.52749500e+00 9.97344000e-01\n",
      " 9.22415000e-01]\n",
      "[-2.35159216e+03 -5.03808844e+03 -4.26715136e+02  1.18997900e+00\n",
      " -1.25594250e+01 -1.59952790e+01 -3.51977300e+00 -4.33067100e+00\n",
      " -3.49233200e+00] [8.73287168e+02 1.48377702e+03 1.92057038e+02 1.49848750e+01\n",
      " 6.33597900e+00 1.17681000e+00 3.85436700e+00 4.19250600e+00\n",
      " 2.82611400e+00]\n",
      "[-6.50218263e+02 -8.98307292e+02 -1.24654564e+02  4.55161000e+00\n",
      "  4.37921800e+00 -6.87111000e+00 -3.62014000e-01 -3.01913000e-01\n",
      " -4.04350000e-01] [ 4.64246403e+03  6.20422723e+03  7.20342395e+02  5.96845100e+00\n",
      "  7.18716100e+00 -4.94787000e+00  6.03130000e-01  1.41511000e-01\n",
      "  1.36546000e-01]\n",
      "[-4.61004212e+03 -7.76335656e+03 -1.74852647e+03  6.33478200e+00\n",
      " -5.58476000e+00 -6.37488700e+00 -2.95956800e+00 -4.33067100e+00\n",
      " -3.94987000e+00] [702.41173817 993.37984108 226.84159644  16.967375     4.14637\n",
      "   8.003626     3.23171      3.509662     3.174194  ]\n",
      "[ -706.22332847 -1009.79644556  -262.44636931    -5.392017\n",
      "   -12.816814     -13.731446      -2.771004      -2.084272\n",
      "    -3.306157  ] [ 3.67111114e+03  7.74838936e+03  1.73316374e+03  7.70074400e+00\n",
      "  1.47610100e+00 -2.63555200e+00  2.71319400e+00  3.27342400e+00\n",
      "  2.15207500e+00]\n",
      "[-4.92882907e+02 -7.80789609e+02 -1.28671827e+02  6.73702800e+00\n",
      "  8.12873000e-01 -7.98028100e+00 -1.37630000e-01 -1.26686000e-01\n",
      " -9.30040000e-02] [ 3.64735850e+03  5.83438329e+03  7.90346065e+02  7.59000600e+00\n",
      "  2.42724600e+00 -5.93253600e+00  3.11252000e-01  1.26451000e-01\n",
      "  1.67590000e-01]\n",
      "[-5.88557098e+03 -6.30397165e+03 -1.00802459e+03  3.43226300e+00\n",
      " -9.02001600e+00 -2.77981000e+00 -4.18170200e+00 -3.77181000e+00\n",
      " -3.79046000e+00] [847.88919702 973.83342379 179.92590409  15.719334     3.113219\n",
      "  11.11445      4.339611     3.960397     3.495926  ]\n",
      "[-810.25701318 -892.25181507 -164.9969765    -4.059576    -13.893661\n",
      "   -6.617312     -1.476576     -1.460983     -1.935928  ] [ 5.96999772e+03  6.46305740e+03  1.05891527e+03  2.31112100e+00\n",
      " -1.78377100e+00 -7.04530000e-01  1.95908700e+00  9.28575000e-01\n",
      "  1.39600400e+00]\n",
      "[-5.93707577e+02 -8.38364266e+02 -2.01212246e+02  5.78708000e+00\n",
      "  6.00975000e-01 -7.75641200e+00 -1.60156000e-01 -1.77187000e-01\n",
      " -2.57460000e-02] [ 6.92574203e+02  3.05494645e+02  1.17052277e+02  6.43714000e+00\n",
      "  1.49944500e+00 -7.26856800e+00  1.00572000e-01 -2.96450000e-02\n",
      "  1.32315000e-01]\n",
      "[-1110.22428966 -1172.414782    -164.44792792     3.616027\n",
      "   -19.6143        -9.304342      -2.920964      -2.532655\n",
      "    -3.150215  ] [7.84427450e+03 7.25423516e+03 9.67631542e+02 1.37751430e+01\n",
      " 1.44096380e+01 8.10538400e+00 2.61290300e+00 2.13833400e+00\n",
      " 3.06236900e+00]\n",
      "[-7.92537655e+03 -7.46537004e+03 -1.02442622e+03 -5.72782100e+00\n",
      " -1.96143000e+01 -1.96137010e+01 -4.17821600e+00 -4.33082700e+00\n",
      " -4.36868100e+00] [1357.01941306 2084.62255711  297.7650343    13.635075      8.246051\n",
      "   10.311753      4.339768      3.028265      4.357965  ]\n",
      "[-6.11056420e+02 -6.56211525e+02 -1.37069117e+02  2.73371900e+00\n",
      "  4.63780500e+00 -1.03159440e+01 -2.73829000e-01 -1.81958000e-01\n",
      " -1.27133000e-01] [ 4.60469582e+03  5.04834514e+03  7.87060150e+02  3.87102300e+00\n",
      "  7.87074000e+00 -5.41955200e+00  1.79315000e-01  2.68656000e-01\n",
      "  1.72610000e-01]\n",
      "[-1.33227600e+04 -1.42461477e+04 -1.91886955e+03  6.46228000e+00\n",
      " -5.88405000e+00 -4.26369200e+00 -3.28444500e+00 -4.33082700e+00\n",
      " -2.05755500e+00] [1789.60981889 1925.70331862  387.77557301   15.839648      2.821711\n",
      "    8.822484      3.523364      2.90962       2.029261  ]\n",
      "[-1.83756384e+03 -1.96041100e+03 -2.72373295e+02  1.92024800e+00\n",
      " -1.21697490e+01 -7.15364100e+00 -1.79727800e+00 -1.90012400e+00\n",
      " -1.76925900e+00] [ 1.33671786e+04  1.43004042e+04  1.91428905e+03  7.97190100e+00\n",
      " -3.88898000e+00  5.26153000e-01  2.19566100e+00  1.27867400e+00\n",
      "  1.46799500e+00]\n",
      "[-1.40997983e+02 -1.73707140e+02 -2.55537045e+02  3.58849300e+00\n",
      "  5.80144600e+00 -7.92640900e+00 -1.66866000e-01 -3.11657000e-01\n",
      " -1.33521000e-01] [ 1.01966189e+03  1.26039154e+03  8.15599720e+02  4.58572900e+00\n",
      "  7.36793300e+00 -5.65898400e+00  1.56847000e-01  2.00610000e-01\n",
      "  1.41188000e-01]\n",
      "[ -947.12988339 -1094.25532095  -710.91557886     7.455924\n",
      "    -7.569056      -3.257477      -2.737121      -2.132621\n",
      "    -1.227697  ] [ 5.36654432e+03  3.89692964e+03  2.22281826e+02  1.22272130e+01\n",
      " -3.12459000e-01  6.55685600e+00  4.34126900e+00  1.09571200e+00\n",
      "  1.68864200e+00]\n",
      "[-5.34973434e+03 -3.89164064e+03 -2.34903310e+02 -1.43898900e+00\n",
      " -1.05122790e+01 -1.96137010e+01 -3.43610800e+00 -2.91738700e+00\n",
      " -2.40108100e+00] [728.06350286 567.26603043 102.61945868   9.378566     9.416875\n",
      "   2.46735      2.492179     4.397762     3.001756  ]\n",
      "[-1.90375474e+02 -1.60540858e+02 -6.11568018e+01  1.94419100e+00\n",
      " -2.29675500e+00 -9.49947900e+00 -5.41474000e-01 -6.57640000e-02\n",
      " -1.26707000e-01] [ 2.97866514e+02  1.03915927e+03  9.24797161e+01  2.90491300e+00\n",
      "  1.19720000e-02 -8.23048800e+00  4.94378000e-01  8.56390000e-02\n",
      "  8.00900000e-02]\n",
      "[-4.85117491e+03 -4.77922100e+03 -4.80844892e+02  7.16860500e+00\n",
      " -9.14691500e+00 -8.80093600e+00 -4.38514000e+00 -3.07518100e+00\n",
      " -3.15037300e+00] [714.6315017  766.92006742  98.43150074  14.214501     8.146088\n",
      "   7.926409     3.603932     2.856434     2.531434  ]\n",
      "[ -792.14434814 -1297.04575988  -392.49551117    -4.342106\n",
      "   -16.440624     -10.76428       -2.978788      -2.835497\n",
      "    -3.156019  ] [4.74382909e+03 4.59311392e+03 4.07249333e+02 3.97397900e+00\n",
      " 9.40969000e-01 3.38138400e+00 3.80438600e+00 2.00620300e+00\n",
      " 2.98612300e+00]\n",
      "[-2.34219037e+02 -4.82362542e+02 -1.22085798e+02  1.28036500e+00\n",
      "  1.32286000e-01 -9.55454800e+00 -2.15850000e-01 -3.78040000e-02\n",
      " -8.56140000e-02] [ 1.58181835e+03  3.09597333e+03  6.35898946e+02  1.94119800e+00\n",
      "  9.15829000e-01 -9.28818000e+00  1.34361000e-01  5.38100000e-02\n",
      "  5.80660000e-02]\n",
      "[-2.40433197e+03 -2.85441521e+03 -5.54343119e+02  6.74241500e+00\n",
      " -7.80908700e+00 -4.26129800e+00 -3.22446900e+00 -2.00537800e+00\n",
      " -2.51192400e+00] [393.22142701 604.79182593 146.0500683   13.084979     2.851041\n",
      "   6.327001     4.046205     1.162368     2.644168  ]\n",
      "[-715.09055148 -525.87218519 -202.25738699   -0.759001    -11.76032\n",
      "  -16.596853     -2.099487     -2.086535     -3.28281   ] [ 2.37471808e+03  2.52257949e+03  1.49043026e+02  7.62771700e+00\n",
      " -6.59038000e-01 -1.40127800e+00  3.44982600e+00  1.85047600e+00\n",
      "  2.11829600e+00]\n",
      "[-2.57539192e+02 -6.51819427e+02 -1.01044708e+02  1.48986800e+00\n",
      " -3.99253000e-01 -9.53120400e+00 -8.26440000e-02 -6.40990000e-02\n",
      " -2.03880000e-02] [ 1.73558010e+03  4.31839652e+03  3.77498770e+02  2.14232100e+00\n",
      "  9.51740000e-02 -9.17205500e+00  1.86605000e-01  3.55040000e-02\n",
      "  5.97740000e-02]\n",
      "[-2.58460165e+03 -5.17781184e+03 -4.27732060e+02  6.47066000e+00\n",
      " -3.74352500e+00  4.78266000e-01 -2.49217600e+00 -9.42956000e-01\n",
      " -1.57663000e+00] [5.47450135e+02 1.09620088e+03 1.25961798e+02 1.30430780e+01\n",
      " 3.74891200e+00 8.20055900e+00 2.05257700e+00 8.25943000e-01\n",
      " 1.60123500e+00]\n",
      "[-352.87338833 -723.54427933 -122.81345547   -5.922359    -19.6143\n",
      "  -19.613701     -3.26755      -3.841241     -4.367001  ] [2.74203020e+03 5.48222438e+03 3.46750179e+02 1.41271090e+01\n",
      " 8.06109000e+00 6.77952800e+00 3.92016500e+00 2.54325200e+00\n",
      " 4.35964500e+00]\n",
      "[-5.84300904e+02 -1.21316039e+03 -5.87551813e+02  1.55152200e+00\n",
      " -3.80039000e+00 -9.61919600e+00 -1.17746900e+00 -4.21823000e-01\n",
      " -1.06689500e+00] [ 1.98954023e+03  2.23000164e+03  3.25911846e+02  5.39082000e+00\n",
      "  2.07109000e+00 -7.98686600e+00  1.69679100e+00  2.20541000e-01\n",
      "  6.64453000e-01]\n",
      "[-2017.56394122 -2286.92188175  -400.25853052     4.161335\n",
      "   -10.036407     -13.882289      -4.386627      -4.329273\n",
      "    -3.198654  ] [371.27966655 494.47499501 141.23101554  14.899278     4.449252\n",
      "   8.553123     4.340019     2.802914     3.910363  ]\n",
      "[-2.12344610e+03 -1.12375729e+03 -1.75532814e+02 -2.19679000e-01\n",
      " -1.57851770e+01 -4.22358700e+00 -2.82389500e+00 -2.39115700e+00\n",
      " -2.35935200e+00] [1182.88812044 1098.42546048  548.10326116    7.566661     -3.382581\n",
      "    8.047322      3.368448      1.9713        1.926672  ]\n",
      "[-3.86820943e+02 -5.63386049e+02 -8.36747094e+01  1.98130000e-01\n",
      " -2.43802000e+00 -1.08013930e+01 -8.73899000e-01 -1.57796000e-01\n",
      " -1.72996000e-01] [ 2.74147544e+03  3.93589836e+03  4.45619417e+02  1.38391900e+00\n",
      "  1.78257400e+00 -8.34421800e+00  6.35204000e-01  2.47810000e-01\n",
      "  3.38871000e-01]\n",
      "[-6.38393523e+03 -6.66209569e+03 -7.95261440e+02  6.78311900e+00\n",
      " -4.72639500e+00 -1.36955300e+00 -2.51602900e+00 -1.49099500e+00\n",
      " -2.47040700e+00] [1.13255235e+03 1.20403663e+03 1.68956917e+02 1.32334270e+01\n",
      " 5.38244000e+00 7.24402600e+00 2.45523600e+00 1.12932900e+00\n",
      " 2.44999100e+00]\n",
      "[-1.08676331e+03 -1.54866497e+03 -3.05180988e+02  3.59747000e-01\n",
      " -1.11114580e+01 -1.16136670e+01 -3.16585000e+00 -2.47944200e+00\n",
      " -2.08783800e+00] [ 6.80801456e+03  7.12112995e+03  8.81475197e+02  8.86199100e+00\n",
      "  8.07486000e-01 -1.82088300e+00  2.83314400e+00  1.58194000e+00\n",
      "  1.65169600e+00]\n",
      "[-3.35405253e+02 -2.69426080e+02 -1.40503450e+02  1.39589100e+00\n",
      "  9.46955000e-01 -9.46176900e+00 -2.16887000e-01 -8.01640000e-02\n",
      " -9.11030000e-02] [ 2.30589949e+03  1.65436004e+03  7.29216804e+02  1.96873300e+00\n",
      "  1.68979400e+00 -9.19540000e+00  1.42246000e-01  1.00135000e-01\n",
      "  7.80100000e-02]\n",
      "[-2.28511347e+03 -1.28636100e+03 -7.11703368e+02  7.57683800e+00\n",
      " -4.10027900e+00 -5.45307200e+00 -2.79180400e+00 -1.22054700e+00\n",
      " -1.96133600e+00] [4.46706993e+03 3.39645861e+03 1.25256319e+02 1.22912610e+01\n",
      " 5.40997500e+00 4.10865900e+00 4.33945100e+00 1.40124200e+00\n",
      " 1.93998800e+00]\n",
      "[-4.18072077e+03 -2.88721105e+03 -2.97984916e+02 -6.97945000e-01\n",
      " -1.71080420e+01 -6.00137200e+00 -2.90699200e+00 -2.09722700e+00\n",
      " -2.86836500e+00] [7.04563910e+02 9.99477182e+02 4.43610004e+02 8.86558200e+00\n",
      " 7.50620000e-01 4.77248600e+00 2.74032700e+00 2.04977700e+00\n",
      " 3.01491300e+00]\n",
      "[-4.56794885e+02 -5.76262028e+02 -1.52413399e+02  1.07086100e+00\n",
      "  8.60161000e-01 -9.58747100e+00 -1.47782000e-01 -4.86930000e-02\n",
      " -1.16745000e-01] [ 3.33563429e+03  4.11668053e+03  7.42397554e+02  1.99447200e+00\n",
      "  1.70954700e+00 -9.23610400e+00  1.00295000e-01  2.52110000e-02\n",
      "  5.75610000e-02]\n",
      "[-3.30894659e+03 -4.07394538e+03 -7.63153707e+02  7.41222800e+00\n",
      " -9.27441300e+00 -1.59821100e+00 -1.60055900e+00 -1.03034900e+00\n",
      " -2.02572800e+00] [488.94391294 704.02946245 125.93127486  12.524707     4.889808\n",
      "   5.397404     2.597046     1.217393     2.117814  ]\n"
     ]
    }
   ],
   "source": [
    "df_custom_normalized, scalers = normalization_group_action_imu(df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subjects and action you want to filter\n",
    "selected_subjects = [1,2,3,4,5]  # Replace with desired subject IDs\n",
    "selected_action = 'sit'    # Replace with the desired action\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_custom = df_filtered[(df_filtered['subject'].isin(selected_subjects)) & (df_filtered['action'] == selected_action)]\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "df_custom = df_custom.reset_index(drop=True)\n",
    "\n",
    "# Verify the result\n",
    "print(df_custom.head())\n",
    "print(f\"New DataFrame shape: {df_custom.shape}\")\n",
    "df_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 253000\n",
    "stop = 255000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time points\n",
    "time = df_custom.index  # Assuming your dataframe has a time-based index\n",
    "\n",
    "# Plot the normalized ECG time-series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time[start:stop], df_custom['ecg'][start:stop], label=\"Normalized ECG Signal\", color='blue')\n",
    "plt.title(\"Normalized ECG Time-Series\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot all PPG signals and ECG on the same graph\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time[start:stop], df_custom['red ppg'][start:stop], label=\" Red PPG\", color='red')\n",
    "plt.plot(time[start:stop], df_custom['green ppg'][start:stop], label=\" Green PPG\", color='green')\n",
    "plt.plot(time[start:stop], df_custom['ir ppg'][start:stop], label=\" IR PPG\", color='purple')\n",
    "plt.title(\" PPG Signals\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\" Value\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot ECG signal\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time[start:stop], df_custom['ecg'][start:stop], label=\" ECG\", color='blue')\n",
    "plt.title(\" ECG Signal\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\" Value\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_custom_normalized, scalers = normalization_group_action(df_custom)\n",
    "# df_custom_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom_normalized, scalers = global_normalization(df_custom)\n",
    "df_custom_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot all PPG signals and ECG on the same graph\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time[start:stop], df_custom_normalized['red ppg'][start:stop], label=\"Normalized Red PPG\", color='red')\n",
    "plt.plot(time[start:stop], df_custom_normalized['green ppg'][start:stop], label=\"Normalized Green PPG\", color='green')\n",
    "plt.plot(time[start:stop], df_custom_normalized['ir ppg'][start:stop], label=\"Normalized IR PPG\", color='purple')\n",
    "plt.title(\"Normalized PPG Signals\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot ECG signal\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time[start:stop], df_custom_normalized['ecg'][start:stop], label=\"Normalized ECG\", color='blue')\n",
    "plt.title(\"Normalized ECG Signal\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time points\n",
    "time = df_custom_normalized.index  # Assuming your dataframe has a time-based index\n",
    "\n",
    "# Plot the normalized ECG time-series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time[253000:255000], df_custom_normalized['ecg'][253000:255000], label=\"Normalized ECG Signal\", color='blue')\n",
    "plt.title(\"Normalized ECG Time-Series\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Normalized Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences_imu(df, sequence_length, sequence_step_size, subset):\n",
    "    '''\n",
    "    Create sequnces with the per (subject, action) pair normalized dataframe\n",
    "    '''\n",
    "    # Retrieve input ppg signals\n",
    "    input_columns = ['red ppg', 'ir ppg', 'green ppg', 'a_x', 'a_y', 'a_z', 'g_x', 'g_y', 'g_z']\n",
    "    x_normalized = df[input_columns].values\n",
    "\n",
    "    # Retrieve target ecg signals\n",
    "    y_normalized = df[['ecg']].values\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_data = torch.tensor(x_normalized, dtype=torch.float32)  # Shape: [samples, 6]\n",
    "    y_data = torch.tensor(y_normalized, dtype=torch.float32)  # Shape: [samples, 1]\n",
    "\n",
    "    # Reshape for sequence length and adjustable stepsize. Sequences are shifted by timestamp / sample stepsize per sequence! \n",
    "    num_sequences = len(df) - sequence_length + 1\n",
    "\n",
    "    x_sequences = torch.stack([x_data[i:i + sequence_length] for i in range(0, int(num_sequences*subset), int(sequence_step_size))])  # [num_sequences, seq_length, 6]\n",
    "    y_sequences = torch.stack([y_data[i:i + sequence_length] for i in range(0, int(num_sequences*subset), int(sequence_step_size))])  # [num_sequences, seq_length, 1]\n",
    "    return x_sequences, y_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg</th>\n",
       "      <th>red ppg</th>\n",
       "      <th>ir ppg</th>\n",
       "      <th>green ppg</th>\n",
       "      <th>action</th>\n",
       "      <th>subject</th>\n",
       "      <th>a_x</th>\n",
       "      <th>a_y</th>\n",
       "      <th>a_z</th>\n",
       "      <th>g_x</th>\n",
       "      <th>g_y</th>\n",
       "      <th>g_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.164368</td>\n",
       "      <td>-0.735236</td>\n",
       "      <td>-0.739668</td>\n",
       "      <td>-0.745664</td>\n",
       "      <td>run</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204395</td>\n",
       "      <td>-0.343275</td>\n",
       "      <td>-0.155174</td>\n",
       "      <td>-0.399232</td>\n",
       "      <td>0.188411</td>\n",
       "      <td>0.079801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.158655</td>\n",
       "      <td>-0.734529</td>\n",
       "      <td>-0.738882</td>\n",
       "      <td>-0.746721</td>\n",
       "      <td>run</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.238707</td>\n",
       "      <td>-0.357213</td>\n",
       "      <td>-0.154050</td>\n",
       "      <td>-0.396621</td>\n",
       "      <td>0.205572</td>\n",
       "      <td>0.089421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.152808</td>\n",
       "      <td>-0.733826</td>\n",
       "      <td>-0.738097</td>\n",
       "      <td>-0.747785</td>\n",
       "      <td>run</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.261582</td>\n",
       "      <td>-0.342525</td>\n",
       "      <td>-0.165288</td>\n",
       "      <td>-0.391091</td>\n",
       "      <td>0.218713</td>\n",
       "      <td>0.096904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.146828</td>\n",
       "      <td>-0.733132</td>\n",
       "      <td>-0.737317</td>\n",
       "      <td>-0.748848</td>\n",
       "      <td>run</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.278031</td>\n",
       "      <td>-0.317048</td>\n",
       "      <td>-0.185923</td>\n",
       "      <td>-0.385254</td>\n",
       "      <td>0.225827</td>\n",
       "      <td>0.101045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.140714</td>\n",
       "      <td>-0.732452</td>\n",
       "      <td>-0.736544</td>\n",
       "      <td>-0.749902</td>\n",
       "      <td>run</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.297565</td>\n",
       "      <td>-0.293818</td>\n",
       "      <td>-0.211666</td>\n",
       "      <td>-0.380107</td>\n",
       "      <td>0.227348</td>\n",
       "      <td>0.101780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16217127</th>\n",
       "      <td>0.621431</td>\n",
       "      <td>0.735613</td>\n",
       "      <td>0.697284</td>\n",
       "      <td>0.705999</td>\n",
       "      <td>walk</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.455802</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>-0.370925</td>\n",
       "      <td>-0.396948</td>\n",
       "      <td>-0.124408</td>\n",
       "      <td>0.033390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16217128</th>\n",
       "      <td>0.563686</td>\n",
       "      <td>0.736206</td>\n",
       "      <td>0.698010</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>walk</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.445030</td>\n",
       "      <td>0.058361</td>\n",
       "      <td>-0.354496</td>\n",
       "      <td>-0.388573</td>\n",
       "      <td>-0.142180</td>\n",
       "      <td>0.029919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16217129</th>\n",
       "      <td>0.504797</td>\n",
       "      <td>0.736785</td>\n",
       "      <td>0.698713</td>\n",
       "      <td>0.707919</td>\n",
       "      <td>walk</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.438941</td>\n",
       "      <td>0.064869</td>\n",
       "      <td>-0.336357</td>\n",
       "      <td>-0.380008</td>\n",
       "      <td>-0.160308</td>\n",
       "      <td>0.025741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16217130</th>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.737347</td>\n",
       "      <td>0.699388</td>\n",
       "      <td>0.708826</td>\n",
       "      <td>walk</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.434258</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>-0.314965</td>\n",
       "      <td>-0.371189</td>\n",
       "      <td>-0.177607</td>\n",
       "      <td>0.021178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16217131</th>\n",
       "      <td>0.386404</td>\n",
       "      <td>0.737888</td>\n",
       "      <td>0.700031</td>\n",
       "      <td>0.709691</td>\n",
       "      <td>walk</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.429341</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>-0.292376</td>\n",
       "      <td>-0.361799</td>\n",
       "      <td>-0.193957</td>\n",
       "      <td>0.016293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16217132 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ecg   red ppg    ir ppg  green ppg action  subject       a_x  \\\n",
       "0        -0.164368 -0.735236 -0.739668  -0.745664    run        1 -0.204395   \n",
       "1        -0.158655 -0.734529 -0.738882  -0.746721    run        1 -0.238707   \n",
       "2        -0.152808 -0.733826 -0.738097  -0.747785    run        1 -0.261582   \n",
       "3        -0.146828 -0.733132 -0.737317  -0.748848    run        1 -0.278031   \n",
       "4        -0.140714 -0.732452 -0.736544  -0.749902    run        1 -0.297565   \n",
       "...            ...       ...       ...        ...    ...      ...       ...   \n",
       "16217127  0.621431  0.735613  0.697284   0.705999   walk       22 -0.455802   \n",
       "16217128  0.563686  0.736206  0.698010   0.706974   walk       22 -0.445030   \n",
       "16217129  0.504797  0.736785  0.698713   0.707919   walk       22 -0.438941   \n",
       "16217130  0.445473  0.737347  0.699388   0.708826   walk       22 -0.434258   \n",
       "16217131  0.386404  0.737888  0.700031   0.709691   walk       22 -0.429341   \n",
       "\n",
       "               a_y       a_z       g_x       g_y       g_z  \n",
       "0        -0.343275 -0.155174 -0.399232  0.188411  0.079801  \n",
       "1        -0.357213 -0.154050 -0.396621  0.205572  0.089421  \n",
       "2        -0.342525 -0.165288 -0.391091  0.218713  0.096904  \n",
       "3        -0.317048 -0.185923 -0.385254  0.225827  0.101045  \n",
       "4        -0.293818 -0.211666 -0.380107  0.227348  0.101780  \n",
       "...            ...       ...       ...       ...       ...  \n",
       "16217127  0.051600 -0.370925 -0.396948 -0.124408  0.033390  \n",
       "16217128  0.058361 -0.354496 -0.388573 -0.142180  0.029919  \n",
       "16217129  0.064869 -0.336357 -0.380008 -0.160308  0.025741  \n",
       "16217130  0.070363 -0.314965 -0.371189 -0.177607  0.021178  \n",
       "16217131  0.074504 -0.292376 -0.361799 -0.193957  0.016293  \n",
       "\n",
       "[16217132 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_custom_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([114, 1000, 9]), y_train shape: torch.Size([114, 1000, 1])\n",
      "x_val shape: torch.Size([32, 1000, 9]), y_val shape: torch.Size([32, 1000, 1])\n",
      "x_test shape: torch.Size([17, 1000, 9]), y_test shape: torch.Size([17, 1000, 1])\n"
     ]
    }
   ],
   "source": [
    "# Ratios for train, validation, and test splits\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "sequence_length = 1000\n",
    "sequence_step_size = 100\n",
    "subset = 0.001\n",
    "\n",
    "# Generate sequences\n",
    "x_data, y_data = sequences_imu(df_custom_normalized, sequence_length, sequence_step_size, subset)\n",
    "\n",
    "# Calculate sizes for each subset\n",
    "total_samples = x_data.size(0)\n",
    "train_size = int(train_ratio * total_samples)\n",
    "val_size = int(val_ratio * total_samples)\n",
    "test_size = total_samples - train_size - val_size  # Remaining samples go to the test set\n",
    "\n",
    "# Split the data\n",
    "X_train = x_data[:train_size]\n",
    "y_train = y_data[:train_size]\n",
    "\n",
    "X_val = x_data[train_size:train_size + val_size]\n",
    "y_val = y_data[train_size:train_size + val_size]\n",
    "\n",
    "X_test = x_data[train_size + val_size:]\n",
    "y_test = y_data[train_size + val_size:]\n",
    "\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"x_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"x_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization \n",
    "d_model = 64  # Embedding dimension\n",
    "input_dim = 9  # 3 PPG signals (red, green, IR)\n",
    "output_dim = 1  # 1 ECG target per time step\n",
    "nhead = 2  # Attention heads\n",
    "num_layers = 2  # Number of transformer layers\n",
    "batch_size = 8  # Batch size\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Convert tensors to Datasets\n",
    "train_dataset = PreprocessedDataset(X_train, y_train)\n",
    "val_dataset = PreprocessedDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders with a reproducible generator\n",
    "gen = torch.Generator(device=device)\n",
    "gen.manual_seed(seed)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, generator=gen)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize the Transformer model\n",
    "model = Point2PointEncoderTransformer(input_dim=input_dim, output_dim=output_dim, d_model=d_model, nhead=nhead, num_layers=num_layers).to(device) \n",
    "\n",
    "X_train_sample = X_train[:1]\n",
    "y_train_sample = y_train[:1]\n",
    "\n",
    "# Call the torchinfo summary method\n",
    "#summary_txt = summary(model, input_data=X_train_sample, depth=1, device=device)\n",
    "#print(summary_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000, 9])\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for batch_X, batch_y in train_loader:\n",
    "    batch_X = batch_X.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "    c +=1\n",
    "    \n",
    "print(batch_X.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of epoch 1 done, starting validation!\n",
      "Checkpoint saved at epoch 1.\n",
      "Epoch 1/10 | Train RMSE: 0.2946 | Val RMSE: 0.2003 | Current LR: 0.001000\n",
      "Training of epoch 2 done, starting validation!\n",
      "Checkpoint saved at epoch 2.\n",
      "Epoch 2/10 | Train RMSE: 0.2192 | Val RMSE: 0.1698 | Current LR: 0.001000\n",
      "Training of epoch 3 done, starting validation!\n",
      "Epoch 3/10 | Train RMSE: 0.2817 | Val RMSE: 0.2661 | Current LR: 0.001000\n",
      "Training of epoch 4 done, starting validation!\n",
      "Epoch 4/10 | Train RMSE: 0.1930 | Val RMSE: 0.2553 | Current LR: 0.001000\n",
      "Training of epoch 5 done, starting validation!\n",
      "Epoch 5/10 | Train RMSE: 0.1762 | Val RMSE: 0.2369 | Current LR: 0.001000\n",
      "Training of epoch 6 done, starting validation!\n",
      "Epoch 6/10 | Train RMSE: 0.1726 | Val RMSE: 0.2387 | Current LR: 0.001000\n",
      "Training of epoch 7 done, starting validation!\n",
      "Epoch 7/10 | Train RMSE: 0.1694 | Val RMSE: 0.2268 | Current LR: 0.001000\n",
      "Training of epoch 8 done, starting validation!\n",
      "Epoch 8/10 | Train RMSE: 0.1670 | Val RMSE: 0.2237 | Current LR: 0.000500\n",
      "Training of epoch 9 done, starting validation!\n",
      "Epoch 9/10 | Train RMSE: 0.1655 | Val RMSE: 0.2317 | Current LR: 0.000500\n",
      "Training of epoch 10 done, starting validation!\n",
      "Epoch 10/10 | Train RMSE: 0.1651 | Val RMSE: 0.2294 | Current LR: 0.000500\n"
     ]
    }
   ],
   "source": [
    "# Loss function: Mean Squared Error for regression tasks\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer: Adam optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)\n",
    "\n",
    "# Number of epochs to train\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize a learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# Clear any residual memory before training\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Arrays for storing losses and epochs\n",
    "training_loss = np.array([])\n",
    "validation_loss = np.array([])\n",
    "epochs = np.array([])\n",
    "best_models = np.array([])\n",
    "\n",
    "# Early stopping and checkpoint parameters\n",
    "patience = 10\n",
    "min_delta = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "\n",
    "### Training\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0 # Initialize running loss\n",
    "    # Iterate through the batches in the train_loader to load the data in batches\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        predictions = model(batch_X)\n",
    "\n",
    "        # Calculate loss (MSE between predicted ECG and actual ECG)\n",
    "        loss = loss_fn(predictions, batch_y)\n",
    "\n",
    "        # Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    avg_train_loss = running_loss / len(X_train)\n",
    "    train_rmse = torch.sqrt(torch.tensor(avg_train_loss)) # MSE needs to be calculated at the end of each batch, scaled by batch size and the RMSE should calculated at the end of the epoch (metric)\n",
    "    training_loss = np.append(training_loss, train_rmse.cpu())\n",
    "\n",
    "    print(f\"Training of epoch {epoch+1} done, starting validation!\")\n",
    "    # Validation metrics with batching\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate through the batches in the val_loader to load the data in batches\n",
    "        for batch_X_val, batch_y_val in val_loader:\n",
    "            batch_X_val = batch_X_val.to(device)\n",
    "            batch_y_val = batch_y_val.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            val_predictions = model(batch_X_val)\n",
    "\n",
    "            # Calculate loss for this batch\n",
    "            val_loss = loss_fn(val_predictions, batch_y_val)\n",
    "\n",
    "            # Accumulate total validation loss\n",
    "            total_val_loss += val_loss.item() * batch_X_val.size(0)  # Weighted by batch size\n",
    "\n",
    "\n",
    "        # Average validation loss over all samples\n",
    "        avg_val_loss = total_val_loss / len(X_val) \n",
    "        val_rmse = torch.sqrt(torch.tensor(avg_val_loss)) # MSE needs to be calculated at the end of each batch, scaled by batch size and the RMSE should calculated at the end of the epoch (metric)\n",
    "        validation_loss = np.append(validation_loss, val_rmse.cpu())\n",
    "\n",
    "        # Step the learning rate scheduler with the validation loss\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stop_counter = 0\n",
    "            # Save checkpoint\n",
    "            #checkpoint_path = f\"{checkpoints_folder}/epoch{epoch+1}.pth\"\n",
    "            #save_checkpoint(model, optimizer, epoch + 1, avg_val_loss, checkpoint_path)\n",
    "\n",
    "            # Save the model\n",
    "            #torch.save(model.state_dict(), f\"../models/{model_family}{model_name}_trained_model_epoch{epoch+1}.pth\")\n",
    "\n",
    "            # Save the epoch of this best model\n",
    "            best_models = np.append(best_models, int(epoch+1))\n",
    "\n",
    "            epochs = np.append(epochs, int(epoch+1))\n",
    "            print(f\"Checkpoint saved at epoch {epoch + 1}.\")\n",
    "        else:\n",
    "            epochs = np.append(epochs, int(epoch+1))\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "            break\n",
    "\n",
    "        #print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f} | Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        # Clear any residual memory before start of new epoch\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (1, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (1, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (2, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (2, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (2, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (3, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (3, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (3, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (4, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (4, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (4, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (5, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (5, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (5, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (6, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (6, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (6, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (7, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (7, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (7, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (8, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (8, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (8, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (9, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (9, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (9, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (10, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (10, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (10, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (11, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (11, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (11, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (12, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (12, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (12, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (13, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (13, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (13, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (14, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (14, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (14, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (15, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (15, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (15, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (16, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (16, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (16, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (17, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (17, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (17, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (18, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (18, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (18, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (19, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (19, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (19, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (20, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (20, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (20, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (21, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (21, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (21, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (22, 'run'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (22, 'sit'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))},\n",
       " (22, 'walk'): {'input_scaler': MinMaxScaler(feature_range=(-1, 1)),\n",
       "  'target_scaler': MinMaxScaler(feature_range=(-1, 1))}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m action \u001b[38;5;241m=\u001b[39m actions[i]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Retrieve the correct scalers\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m scaler_input \u001b[38;5;241m=\u001b[39m scalers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_scaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     77\u001b[0m scaler_target \u001b[38;5;241m=\u001b[39m scalers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_scaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Inverse transform predictions and actuals for the current sequence\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_scaler'"
     ]
    }
   ],
   "source": [
    "### Validation\n",
    "# Initialize storage for aggregated predictions and actual values\n",
    "ecg_predictions = []\n",
    "ecg_actuals = []\n",
    "ppg = []\n",
    "subjects = []  # Store subject info for each batch\n",
    "actions = []   # Store action info for each batch\n",
    "\n",
    "# Loss function: Mean Squared Error for regression tasks\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Test Loss\n",
    "test_loss = np.array([])\n",
    "running_test_loss = 0\n",
    "\n",
    "# Convert tensors to Datasets\n",
    "test_dataset = PreprocessedDataset(X_test, y_test)\n",
    "# Create DataLoaders for each set\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Iterate over the validation set in batches\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Iterate through the batches in the test_loader to load the data in batches\n",
    "    for batch_idx, (batch_X_test, batch_y_test) in enumerate(test_loader):\n",
    "        # Move the batch data to the device (GPU or CPU)\n",
    "        batch_X_test = batch_X_test.to(device)\n",
    "        batch_y_test = batch_y_test.to(device)\n",
    "        \n",
    "        # Get the start and end index of the current batch in df_test\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + len(batch_X_test)\n",
    "        \n",
    "        # Retrieve the corresponding (subject, action) pair for this batch from df_test\n",
    "        batch_subjects = df_test.iloc[start_idx:end_idx]['subject'].values\n",
    "        batch_actions = df_test.iloc[start_idx:end_idx]['action'].values\n",
    "\n",
    "        # Forward pass to get predictions\n",
    "        batch_predictions = model(batch_X_test)\n",
    "\n",
    "        # Calculate loss for this batch\n",
    "        loss = loss_fn(batch_predictions, batch_y_test)\n",
    "\n",
    "        # Accumulate total validation loss\n",
    "        running_test_loss += loss.item() * batch_X_test.size(0)\n",
    "\n",
    "        # Store predictions, actuals, subjects, and actions\n",
    "        ecg_predictions.append(batch_predictions.cpu())  # Move to CPU for numpy/scaler operations\n",
    "        ecg_actuals.append(batch_y_test.cpu())\n",
    "        ppg.append(batch_X_test.cpu())\n",
    "        subjects.extend(batch_subjects)\n",
    "        actions.extend(batch_actions)\n",
    "\n",
    "# Average the test loss over all samples\n",
    "avg_test_loss = running_test_loss / len(X_test)\n",
    "test_rmse = torch.sqrt(torch.tensor(avg_test_loss))\n",
    "test_loss = np.append(test_loss, test_rmse.cpu())\n",
    "\n",
    "# Concatenate all batches\n",
    "ecg_predictions = torch.cat(ecg_predictions, dim=0)\n",
    "ecg_actuals = torch.cat(ecg_actuals, dim=0)\n",
    "ppg = torch.cat(ppg, dim=0)\n",
    "\n",
    "# Initialize lists for original scale data\n",
    "ecg_predictions_original_scale = []\n",
    "ecg_actuals_original_scale = []\n",
    "ppg_original_scale = []\n",
    "\n",
    "# Process each sequence\n",
    "for i in range(len(ecg_predictions)):\n",
    "    # Get subject and action for the current sequence\n",
    "    subject = subjects[i]\n",
    "    action = actions[i]\n",
    "\n",
    "    # Retrieve the correct scalers\n",
    "    scaler_input = scalers['input_scaler']\n",
    "    scaler_target = scalers['target_scaler']\n",
    "\n",
    "    # Inverse transform predictions and actuals for the current sequence\n",
    "    ecg_pred = ecg_predictions[i].squeeze(-1).numpy()  # Shape: [sequence_length]\n",
    "    ecg_act = ecg_actuals[i].squeeze(-1).numpy()       # Shape: [sequence_length]\n",
    "    ppg_seq = ppg[i].numpy()                          # Shape: [sequence_length, 3]\n",
    "\n",
    "    ecg_predictions_original_scale.append(scaler_target.inverse_transform(ecg_pred.reshape(-1, 1)).flatten())\n",
    "    ecg_actuals_original_scale.append(scaler_target.inverse_transform(ecg_act.reshape(-1, 1)).flatten())\n",
    "    ppg_original_scale.append(scaler_input.inverse_transform(ppg_seq))\n",
    "\n",
    "# Convert back to arrays\n",
    "ecg_predictions_original_scale = np.array(ecg_predictions_original_scale)\n",
    "ecg_actuals_original_scale = np.array(ecg_actuals_original_scale)\n",
    "ppg_original_scale = np.array(ppg_original_scale)\n",
    "\n",
    "# Separate PPG channels \n",
    "red_ppg = ppg_original_scale[:, :, 0]  # Red PPG\n",
    "ir_ppg = ppg_original_scale[:, :, 1]   # IR PPG\n",
    "green_ppg = ppg_original_scale[:, :, 2]  # Green PPG\n",
    "\n",
    "\n",
    "### Normalized Evaluation metrics\n",
    "# Predictions and actual values (normalized and flattened)\n",
    "ecg_predictions_arr = np.array(ecg_predictions).flatten()\n",
    "ecg_actuals_arr = np.array(ecg_actuals).flatten()\n",
    "\n",
    "# Calculate the range of the actual data for normalization\n",
    "actual_range_normalized = np.ptp(ecg_actuals)  # Peak-to-peak (max - min)\n",
    "\n",
    "# Euclidean Distance\n",
    "euclidean_distance_normalized = euclidean(ecg_predictions_arr, ecg_actuals_arr)\n",
    "\n",
    "# Dynamic Time Warping (DTW)\n",
    "downsampling_factor_dtw = 10\n",
    "batch_size_dtw = 10 \n",
    "dtw_distance_normalized = compute_batched_dtw(ecg_predictions_arr, ecg_actuals_arr, batch_size_dtw, downsampling_factor_dtw)\n",
    "# dtw_distance = alignment.distance\n",
    "\n",
    "# Pearson Correlation\n",
    "pearson_corr_normalized, _ = pearsonr(ecg_predictions_arr, ecg_actuals_arr)\n",
    "\n",
    "# Spearman Correlation\n",
    "spearman_corr_normalized, _ = spearmanr(ecg_predictions_arr, ecg_actuals_arr)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse_normalized = np.mean((ecg_predictions_arr - ecg_actuals_arr) ** 2)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_normalized = np.mean(np.abs(ecg_predictions_arr - ecg_actuals_arr))\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_normalized = np.sqrt(mse_normalized)\n",
    "\n",
    "# Normalized Root Mean Squared Error (NRMSE)\n",
    "nrmse_normalized = rmse_normalized / actual_range_normalized\n",
    "\n",
    "# Normalized Mean Absolute Error (NMAE)\n",
    "nmae_normalized = mae_normalized / actual_range_normalized\n",
    "\n",
    "# Print metrics\n",
    "metrics_normalized = {\n",
    "    \"Training_loss\": training_loss,\n",
    "    \"Validation_loss\": validation_loss,\n",
    "    \"Test_loss\": test_loss,\n",
    "    \"Epochs\": epochs, \n",
    "    \"Euclidean Distance\": euclidean_distance_normalized,\n",
    "    \"DTW Distance\": dtw_distance_normalized,\n",
    "    \"Pearson Correlation\": pearson_corr_normalized,\n",
    "    \"Spearman Correlation\": spearman_corr_normalized,\n",
    "    \"MSE\": mse_normalized,\n",
    "    \"MAE\": mae_normalized,\n",
    "    \"RMSE\": rmse_normalized,\n",
    "    \"NRMSE\": nrmse_normalized,\n",
    "    \"NMAE\": nmae_normalized,\n",
    "    # \"Parameters\": config['parameters'],  # Add config file entries\n",
    "    # \"General\": config['general'],\n",
    "    # \"Output\": config['output'],\n",
    "}\n",
    "\n",
    "for metric, value in metrics_normalized.items():\n",
    "    #print(f\"{metric}: {value:.4f}\")\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_original_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_predictions_original_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots\n",
    "# Call a plot(...) method to create them\n",
    "# Randomly select an index from the validation data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, training_loss,  label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    "plt.yscale('log')\n",
    "plt.title(f\"Training and Validation Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "#plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(f\"{results_folder}/{model_name}_loss_functions.png\")\n",
    "\n",
    "    # Repeat test loss across all epochs for visualization\n",
    "test_losses = [test_loss] * len(epochs)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, training_loss, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, validation_loss, label=\"Validation Loss\", marker='o')\n",
    "plt.plot(epochs, test_losses, label=\"Test Loss\", linestyle='--', color='red')\n",
    "\n",
    "# Add labels, title, legend\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss\")\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(f\"{results_folder}/{model_name}_test_loss.png\")\n",
    "\n",
    "#random_index = np.random.randint(0, len(ecg_predictions_original_scale))\n",
    "random_index = 1\n",
    "ppg_scaling_factor = 100\n",
    "\n",
    "# Select the corresponding actual and predicted ECG signals\n",
    "ecg_predictions_random = ecg_predictions_original_scale[random_index]  # Predicted ECG signal\n",
    "ecg_actuals_random = ecg_actuals_original_scale[random_index]  # Actual ECG signal\n",
    "\n",
    "# Set the opacity value of alpha for the ppg signals\n",
    "alpha = 0.3\n",
    "\n",
    "# Plot the actual and predicted ECG\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ecg_actuals_random, label='Actual ECG')\n",
    "plt.plot(ecg_predictions_random, label='Predicted ECG')\n",
    "plt.title(f\"ECG Prediction vs Actual (Sequence {random_index})\")\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('ECG Signal')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(f\"{results_folder}/{model_name}_random_seq.png\")\n",
    "\n",
    "# Plot the actual and predicted ECG with the input ppg signals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ecg_actuals_random, label='Actual ECG')\n",
    "plt.plot(ecg_predictions_random, label='Predicted ECG')\n",
    "plt.plot(ppg_scaling_factor*red_ppg[random_index], label=\"Red PPG\", alpha=alpha)\n",
    "plt.plot(ppg_scaling_factor*ir_ppg[random_index], label=\"IR PPG\", alpha=alpha)\n",
    "plt.plot(ppg_scaling_factor*green_ppg[random_index], label=\"Green PPG\", alpha=alpha)\n",
    "plt.title(f\"ECG Prediction vs Actual (Sequence {random_index}) with PPG signals\")\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('ECG Signal')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(f\"{results_folder}/{model_name}_random_seq_ppg.png\")\n",
    "\n",
    "print(\"Evaluation finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

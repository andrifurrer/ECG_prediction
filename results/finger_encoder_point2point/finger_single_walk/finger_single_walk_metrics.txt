Training_loss: [0.32228455 0.28689179 0.28114289 0.27819681 0.2762956  0.27526242
 0.27439767 0.27384672 0.27336347 0.27302247 0.27267724 0.27237755
 0.2723133  0.27193841 0.27182019 0.27167496 0.27134314 0.27111265
 0.27086037 0.27062398 0.27029863 0.26963681 0.26865476 0.26746887
 0.26639304 0.26506212 0.26391575 0.26291952 0.2619305  0.26101932
 0.26001725 0.25911808 0.2578803  0.25641379 0.25473961 0.25273696
 0.2506327  0.24788362 0.24518566 0.24252594 0.2390599  0.23578683
 0.23076615 0.22559193 0.21937928 0.21443114 0.20918094 0.20409444
 0.19971769 0.19576284 0.19239129 0.18880452 0.18601851 0.18329142
 0.18006656 0.17821623 0.17586823 0.17377232 0.17203224 0.16920014
 0.16865446 0.16653724 0.16510005 0.16494596 0.16220427 0.1606525
 0.1594785  0.15879031 0.15751278 0.1560993  0.15551572 0.15427348
 0.15329084 0.15194602 0.15140258 0.15099522 0.15033886 0.14976679
 0.14786237 0.14745262 0.1471597  0.14607997 0.14543368 0.14489633
 0.14354686 0.14353108 0.14266913 0.14155525 0.14139774 0.14132035
 0.14040573 0.14003232 0.13977093 0.13831231 0.13753125 0.13743024
 0.13414535 0.1337337  0.13332972 0.1336289  0.13282599 0.1324883
 0.13255374 0.1321865  0.13177176 0.13134941 0.13126001 0.13109574
 0.13078672 0.13013017 0.13014548 0.13059232 0.12948669 0.12887231
 0.12943658 0.1291697  0.12890857 0.12873453 0.12797433 0.12794171
 0.12767319 0.12771362 0.12712291 0.12559634 0.1248059  0.12509809
 0.12498608 0.12482986 0.12469687 0.12457247 0.12389601 0.12349749
 0.12330103 0.12341288]
Validation_loss: [0.27596086 0.27214158 0.27146047 0.26992685 0.26950681 0.26964223
 0.26891932 0.26892066 0.26861835 0.2684513  0.26830247 0.26835418
 0.2681182  0.26816285 0.26778641 0.26776975 0.26765099 0.26741987
 0.26728666 0.26669315 0.26646972 0.26518524 0.2635811  0.26216409
 0.26007992 0.25946259 0.25775239 0.25614715 0.25501239 0.25405398
 0.2531271  0.25245082 0.25115824 0.24912791 0.24698325 0.24517864
 0.24181114 0.23949139 0.23728314 0.23348141 0.22933769 0.22587641
 0.21885522 0.21347877 0.20813739 0.20160545 0.19901505 0.19436094
 0.1889554  0.18483524 0.18190189 0.17921683 0.17498858 0.17347747
 0.17129876 0.16894886 0.16706671 0.16361217 0.16419455 0.15870209
 0.15984167 0.15774858 0.15875393 0.16071658 0.15758209 0.15461686
 0.15467486 0.15702292 0.15428786 0.15135638 0.15510416 0.1503422
 0.15072143 0.14925425 0.15058909 0.1488343  0.1513826  0.14795263
 0.14844409 0.14784443 0.14552532 0.14395773 0.14679933 0.14615688
 0.14475933 0.14528781 0.1427166  0.14192259 0.1457824  0.14080493
 0.14507414 0.14081787 0.14435652 0.14120963 0.14116345 0.14106373
 0.1391084  0.13998483 0.14127228 0.13751464 0.13831456 0.13746701
 0.13812819 0.13751687 0.13814323 0.13907321 0.13794985 0.13707446
 0.13927756 0.13846147 0.13786906 0.13615316 0.1380446  0.1393372
 0.13667475 0.13703652 0.13571504 0.13582869 0.13721344 0.13712227
 0.13655315 0.13710621 0.13858847 0.1334915  0.1347651  0.13481492
 0.13699138 0.13561985 0.13515587 0.1349712  0.13592839 0.1346985
 0.13406017 0.13500632]
Test_loss: [0.14822476]
Epochs: [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.
  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.
  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.
  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.
  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.
  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.
  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.
  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.
 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.
 127. 128. 129. 130. 131. 132. 133. 134.]
Euclidean Distance: 73.06743621826172
DTW Distance: 0.10005021386936981
Pearson Correlation: 0.8446844726971381
Spearman Correlation: 0.7842399136679438
MSE: 0.02197057567536831
MAE: 0.1002541184425354
RMSE: 0.14822474122047424
NRMSE: 0.08940083533525467
NMAE: 0.06046764925122261
Parameters: {'subject': [10], 'action': 'walk', 'sequence_length': 1000, 'sequence_step_size': 100, 'subset': 1, 'd_model': 144, 'input_dim': 3, 'output_dim': 1, 'nhead': 6, 'num_layers': 4, 'batch_size': 16, 'dropout': 0.1, 'num_epochs': 300, 'learning_rate': 0.001, 'ppg_scaling_factor': 100}
General: {'model_name': 'finger_single_walk', 'model_type': 'encoder', 'dataset': 'Finger', 'normalization': 'subject_wise', 'train': True, 'eval': True, 'use_dataloader': True, 'train_shuffling': True, 'filter': 1, 'validation_set_subjects': 1, 'test_set_subjects': 1, 'random_seed': 17}
Output: {'model_family': 'finger_encoder_point2point/', 'results': '../results/', 'checkpoints': '../models/checkpoints/', 'model_summary': '../models/model_summary/'}
